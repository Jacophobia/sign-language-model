{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "         x1        y1            z1        x2        y2        z2        x3  \\\n0  0.284234  0.599662  1.510391e-09  0.352661  0.574240 -0.018644  0.401655   \n1  0.285704  0.594281 -4.252064e-09  0.351391  0.575788 -0.023778  0.397199   \n2  0.282022  0.592181 -4.262098e-09  0.348222  0.574958 -0.024807  0.395815   \n3  0.279870  0.594496 -3.989998e-09  0.345210  0.575632 -0.021771  0.391491   \n4  0.275030  0.592625 -4.403823e-09  0.340713  0.573089 -0.021498  0.387466   \n\n         y3        z3        x4  ...       x19       y19       z19       x20  \\\n0  0.505305 -0.031250  0.417682  ...  0.264750  0.411588 -0.051163  0.270928   \n1  0.503982 -0.038397  0.411797  ...  0.260840  0.409029 -0.054180  0.269301   \n2  0.503679 -0.039821  0.411231  ...  0.257454  0.408016 -0.052401  0.265423   \n3  0.502638 -0.035953  0.406466  ...  0.254278  0.407087 -0.054067  0.262207   \n4  0.500672 -0.035819  0.402215  ...  0.248197  0.406337 -0.052727  0.256451   \n\n        y20       z20       x21       y21       z21  symbol  \n0  0.466022 -0.052875  0.276105  0.505524 -0.052011       0  \n1  0.466309 -0.058145  0.274917  0.504831 -0.057939       0  \n2  0.464812 -0.056430  0.270709  0.503389 -0.056365       0  \n3  0.463662 -0.057304  0.266132  0.502502 -0.056816       0  \n4  0.461449 -0.056080  0.261073  0.500557 -0.055821       0  \n\n[5 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>x4</th>\n      <th>...</th>\n      <th>x19</th>\n      <th>y19</th>\n      <th>z19</th>\n      <th>x20</th>\n      <th>y20</th>\n      <th>z20</th>\n      <th>x21</th>\n      <th>y21</th>\n      <th>z21</th>\n      <th>symbol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.284234</td>\n      <td>0.599662</td>\n      <td>1.510391e-09</td>\n      <td>0.352661</td>\n      <td>0.574240</td>\n      <td>-0.018644</td>\n      <td>0.401655</td>\n      <td>0.505305</td>\n      <td>-0.031250</td>\n      <td>0.417682</td>\n      <td>...</td>\n      <td>0.264750</td>\n      <td>0.411588</td>\n      <td>-0.051163</td>\n      <td>0.270928</td>\n      <td>0.466022</td>\n      <td>-0.052875</td>\n      <td>0.276105</td>\n      <td>0.505524</td>\n      <td>-0.052011</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.285704</td>\n      <td>0.594281</td>\n      <td>-4.252064e-09</td>\n      <td>0.351391</td>\n      <td>0.575788</td>\n      <td>-0.023778</td>\n      <td>0.397199</td>\n      <td>0.503982</td>\n      <td>-0.038397</td>\n      <td>0.411797</td>\n      <td>...</td>\n      <td>0.260840</td>\n      <td>0.409029</td>\n      <td>-0.054180</td>\n      <td>0.269301</td>\n      <td>0.466309</td>\n      <td>-0.058145</td>\n      <td>0.274917</td>\n      <td>0.504831</td>\n      <td>-0.057939</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.282022</td>\n      <td>0.592181</td>\n      <td>-4.262098e-09</td>\n      <td>0.348222</td>\n      <td>0.574958</td>\n      <td>-0.024807</td>\n      <td>0.395815</td>\n      <td>0.503679</td>\n      <td>-0.039821</td>\n      <td>0.411231</td>\n      <td>...</td>\n      <td>0.257454</td>\n      <td>0.408016</td>\n      <td>-0.052401</td>\n      <td>0.265423</td>\n      <td>0.464812</td>\n      <td>-0.056430</td>\n      <td>0.270709</td>\n      <td>0.503389</td>\n      <td>-0.056365</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.279870</td>\n      <td>0.594496</td>\n      <td>-3.989998e-09</td>\n      <td>0.345210</td>\n      <td>0.575632</td>\n      <td>-0.021771</td>\n      <td>0.391491</td>\n      <td>0.502638</td>\n      <td>-0.035953</td>\n      <td>0.406466</td>\n      <td>...</td>\n      <td>0.254278</td>\n      <td>0.407087</td>\n      <td>-0.054067</td>\n      <td>0.262207</td>\n      <td>0.463662</td>\n      <td>-0.057304</td>\n      <td>0.266132</td>\n      <td>0.502502</td>\n      <td>-0.056816</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.275030</td>\n      <td>0.592625</td>\n      <td>-4.403823e-09</td>\n      <td>0.340713</td>\n      <td>0.573089</td>\n      <td>-0.021498</td>\n      <td>0.387466</td>\n      <td>0.500672</td>\n      <td>-0.035819</td>\n      <td>0.402215</td>\n      <td>...</td>\n      <td>0.248197</td>\n      <td>0.406337</td>\n      <td>-0.052727</td>\n      <td>0.256451</td>\n      <td>0.461449</td>\n      <td>-0.056080</td>\n      <td>0.261073</td>\n      <td>0.500557</td>\n      <td>-0.055821</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 64 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data.\n",
    "# The data is stored in a bunch of csv files\n",
    "# for example data for the letter A is stored in the file \"training_data_0/A.csv\"\n",
    "# we will load all the data into a pandas dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "num_to_letter = dict()\n",
    "letter_to_num = dict()\n",
    "\n",
    "# index and loop through the letters\n",
    "for i, letter in enumerate(\"ABCDEFGHIKLMNOPQRSTUVWXY\"):\n",
    "    # read the csv file\n",
    "    df_letter = pd.read_csv(f\"training_data_0/{letter}.csv\")\n",
    "    # drop the \"'symbol'\" column\n",
    "    df_letter = df_letter.drop(columns=[\"'symbol'\"])\n",
    "    # add a column to the dataframe with the letter\n",
    "    df_letter[\"symbol\"] = i\n",
    "    # add the letter to the letter maps\n",
    "    num_to_letter[i] = letter\n",
    "    letter_to_num[letter] = i\n",
    "    # add the dataframe to the main dataframe\n",
    "    df = pd.concat([df, df_letter])\n",
    "\n",
    "# rename the \"'symbol'\" column to \"symbol\"\n",
    "df = df.rename(columns={\"'symbol'\": \"symbol\"})\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "4     375\n2     313\n17    298\n11    283\n14    260\n20    257\n12    256\n19    252\n15    248\n10    247\n22    246\n9     245\n21    244\n3     243\n7     241\n18    238\n6     237\n5     237\n1     234\n23    233\n16    233\n13    233\n8     233\n0     225\nName: symbol, dtype: int64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"symbol\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                x1           y1            z1           x2           y2  \\\ncount  6111.000000  6111.000000  6.111000e+03  6111.000000  6111.000000   \nmean      0.440433     0.622750  5.929709e-10     0.486052     0.603479   \nstd       0.191912     0.181983  5.487365e-09     0.196405     0.182482   \nmin       0.090501     0.141086 -1.969110e-08     0.109391     0.128427   \n25%       0.289168     0.476999 -2.008002e-09     0.327600     0.453367   \n50%       0.390545     0.595534  1.151827e-09     0.441132     0.579819   \n75%       0.626650     0.792995  3.734280e-09     0.678022     0.777037   \nmax       0.836572     1.025575  1.916064e-08     0.898871     0.997497   \n\n                z2           x3           y3           z3           x4  ...  \\\ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000  ...   \nmean     -0.018906     0.518731     0.554779    -0.037185     0.521704  ...   \nstd       0.022592     0.204327     0.187479     0.033304     0.217539  ...   \nmin      -0.107338     0.103584     0.105467    -0.156331     0.059861  ...   \n25%      -0.031281     0.355535     0.392496    -0.053778     0.344039  ...   \n50%      -0.019073     0.478165     0.540500    -0.036178     0.477882  ...   \n75%      -0.007548     0.720200     0.731449    -0.021938     0.738128  ...   \nmax       0.082677     0.945384     0.950460     0.117195     0.976453  ...   \n\n               x19          y19          z19          x20          y20  \\\ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000   \nmean      0.430614     0.464734    -0.072318     0.439989     0.486142   \nstd       0.220695     0.194340     0.026841     0.221597     0.198481   \nmin       0.023418     0.080981    -0.191882     0.025751     0.072168   \n25%       0.251514     0.305164    -0.088480     0.258871     0.333067   \n50%       0.379583     0.441283    -0.073844     0.391482     0.463063   \n75%       0.647629     0.627818    -0.056358     0.659670     0.630992   \nmax       0.916674     0.986162     0.053344     0.903740     1.020965   \n\n               z20          x21          y21          z21       symbol  \ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000  \nmean     -0.076378     0.445179     0.497874    -0.077505    11.356079  \nstd       0.026343     0.219653     0.201887     0.027505     6.902894  \nmin      -0.199254     0.031057     0.041557    -0.197314     0.000000  \n25%      -0.090959     0.265973     0.349207    -0.092341     5.000000  \n50%      -0.075681     0.394272     0.477647    -0.075551    11.000000  \n75%      -0.061090     0.659340     0.644602    -0.061332    17.000000  \nmax       0.040676     0.890713     1.031843     0.034286    23.000000  \n\n[8 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>x4</th>\n      <th>...</th>\n      <th>x19</th>\n      <th>y19</th>\n      <th>z19</th>\n      <th>x20</th>\n      <th>y20</th>\n      <th>z20</th>\n      <th>x21</th>\n      <th>y21</th>\n      <th>z21</th>\n      <th>symbol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6.111000e+03</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>...</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.440433</td>\n      <td>0.622750</td>\n      <td>5.929709e-10</td>\n      <td>0.486052</td>\n      <td>0.603479</td>\n      <td>-0.018906</td>\n      <td>0.518731</td>\n      <td>0.554779</td>\n      <td>-0.037185</td>\n      <td>0.521704</td>\n      <td>...</td>\n      <td>0.430614</td>\n      <td>0.464734</td>\n      <td>-0.072318</td>\n      <td>0.439989</td>\n      <td>0.486142</td>\n      <td>-0.076378</td>\n      <td>0.445179</td>\n      <td>0.497874</td>\n      <td>-0.077505</td>\n      <td>11.356079</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.191912</td>\n      <td>0.181983</td>\n      <td>5.487365e-09</td>\n      <td>0.196405</td>\n      <td>0.182482</td>\n      <td>0.022592</td>\n      <td>0.204327</td>\n      <td>0.187479</td>\n      <td>0.033304</td>\n      <td>0.217539</td>\n      <td>...</td>\n      <td>0.220695</td>\n      <td>0.194340</td>\n      <td>0.026841</td>\n      <td>0.221597</td>\n      <td>0.198481</td>\n      <td>0.026343</td>\n      <td>0.219653</td>\n      <td>0.201887</td>\n      <td>0.027505</td>\n      <td>6.902894</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.090501</td>\n      <td>0.141086</td>\n      <td>-1.969110e-08</td>\n      <td>0.109391</td>\n      <td>0.128427</td>\n      <td>-0.107338</td>\n      <td>0.103584</td>\n      <td>0.105467</td>\n      <td>-0.156331</td>\n      <td>0.059861</td>\n      <td>...</td>\n      <td>0.023418</td>\n      <td>0.080981</td>\n      <td>-0.191882</td>\n      <td>0.025751</td>\n      <td>0.072168</td>\n      <td>-0.199254</td>\n      <td>0.031057</td>\n      <td>0.041557</td>\n      <td>-0.197314</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.289168</td>\n      <td>0.476999</td>\n      <td>-2.008002e-09</td>\n      <td>0.327600</td>\n      <td>0.453367</td>\n      <td>-0.031281</td>\n      <td>0.355535</td>\n      <td>0.392496</td>\n      <td>-0.053778</td>\n      <td>0.344039</td>\n      <td>...</td>\n      <td>0.251514</td>\n      <td>0.305164</td>\n      <td>-0.088480</td>\n      <td>0.258871</td>\n      <td>0.333067</td>\n      <td>-0.090959</td>\n      <td>0.265973</td>\n      <td>0.349207</td>\n      <td>-0.092341</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.390545</td>\n      <td>0.595534</td>\n      <td>1.151827e-09</td>\n      <td>0.441132</td>\n      <td>0.579819</td>\n      <td>-0.019073</td>\n      <td>0.478165</td>\n      <td>0.540500</td>\n      <td>-0.036178</td>\n      <td>0.477882</td>\n      <td>...</td>\n      <td>0.379583</td>\n      <td>0.441283</td>\n      <td>-0.073844</td>\n      <td>0.391482</td>\n      <td>0.463063</td>\n      <td>-0.075681</td>\n      <td>0.394272</td>\n      <td>0.477647</td>\n      <td>-0.075551</td>\n      <td>11.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.626650</td>\n      <td>0.792995</td>\n      <td>3.734280e-09</td>\n      <td>0.678022</td>\n      <td>0.777037</td>\n      <td>-0.007548</td>\n      <td>0.720200</td>\n      <td>0.731449</td>\n      <td>-0.021938</td>\n      <td>0.738128</td>\n      <td>...</td>\n      <td>0.647629</td>\n      <td>0.627818</td>\n      <td>-0.056358</td>\n      <td>0.659670</td>\n      <td>0.630992</td>\n      <td>-0.061090</td>\n      <td>0.659340</td>\n      <td>0.644602</td>\n      <td>-0.061332</td>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.836572</td>\n      <td>1.025575</td>\n      <td>1.916064e-08</td>\n      <td>0.898871</td>\n      <td>0.997497</td>\n      <td>0.082677</td>\n      <td>0.945384</td>\n      <td>0.950460</td>\n      <td>0.117195</td>\n      <td>0.976453</td>\n      <td>...</td>\n      <td>0.916674</td>\n      <td>0.986162</td>\n      <td>0.053344</td>\n      <td>0.903740</td>\n      <td>1.020965</td>\n      <td>0.040676</td>\n      <td>0.890713</td>\n      <td>1.031843</td>\n      <td>0.034286</td>\n      <td>23.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 64 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "x1        float64\ny1        float64\nz1        float64\nx2        float64\ny2        float64\n           ...   \nz20       float64\nx21       float64\ny21       float64\nz21       float64\nsymbol      int64\nLength: 64, dtype: object"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.84234434e-01  5.99662066e-01  1.51039137e-09  3.52660865e-01\n",
      "  5.74240446e-01 -1.86437536e-02  4.01654959e-01  5.05305409e-01\n",
      " -3.12500969e-02  4.17681813e-01  4.36548412e-01 -4.56334427e-02\n",
      "  4.22503233e-01  3.77860457e-01 -5.84865883e-02  3.74746442e-01\n",
      "  4.36910540e-01 -8.12254008e-03  3.80444705e-01  3.89682174e-01\n",
      " -2.00392306e-02  3.67883712e-01  4.49001282e-01 -2.07441952e-02\n",
      "  3.63591522e-01  4.97271508e-01 -2.23034602e-02  3.35153967e-01\n",
      "  4.29939628e-01 -1.52731035e-02  3.40880424e-01  3.88413638e-01\n",
      " -4.07350659e-02  3.35393161e-01  4.62964505e-01 -5.23742251e-02\n",
      "  3.34779263e-01  5.15209615e-01 -5.54651171e-02  2.94720203e-01\n",
      "  4.33333546e-01 -2.50072163e-02  3.02414715e-01  3.95723999e-01\n",
      " -5.02379835e-02  3.02014083e-01  4.72031504e-01 -5.67812920e-02\n",
      "  3.04903924e-01  5.23163736e-01 -5.66067770e-02  2.54041135e-01\n",
      "  4.42956179e-01 -3.69402952e-02  2.64749527e-01  4.11588371e-01\n",
      " -5.11631295e-02  2.70927608e-01  4.66022164e-01 -5.28754666e-02\n",
      "  2.76105493e-01  5.05524457e-01 -5.20110615e-02  0.00000000e+00]\n",
      "[ 2.84234434e-01  5.99662066e-01  1.51039137e-09  3.52660865e-01\n",
      "  5.74240446e-01 -1.86437536e-02  4.01654959e-01  5.05305409e-01\n",
      " -3.12500969e-02  4.17681813e-01  4.36548412e-01 -4.56334427e-02\n",
      "  4.22503233e-01  3.77860457e-01 -5.84865883e-02  3.74746442e-01\n",
      "  4.36910540e-01 -8.12254008e-03  3.80444705e-01  3.89682174e-01\n",
      " -2.00392306e-02  3.67883712e-01  4.49001282e-01 -2.07441952e-02\n",
      "  3.63591522e-01  4.97271508e-01 -2.23034602e-02  3.35153967e-01\n",
      "  4.29939628e-01 -1.52731035e-02  3.40880424e-01  3.88413638e-01\n",
      " -4.07350659e-02  3.35393161e-01  4.62964505e-01 -5.23742251e-02\n",
      "  3.34779263e-01  5.15209615e-01 -5.54651171e-02  2.94720203e-01\n",
      "  4.33333546e-01 -2.50072163e-02  3.02414715e-01  3.95723999e-01\n",
      " -5.02379835e-02  3.02014083e-01  4.72031504e-01 -5.67812920e-02\n",
      "  3.04903924e-01  5.23163736e-01 -5.66067770e-02  2.54041135e-01\n",
      "  4.42956179e-01 -3.69402952e-02  2.64749527e-01  4.11588371e-01\n",
      " -5.11631295e-02  2.70927608e-01  4.66022164e-01 -5.28754666e-02\n",
      "  2.76105493e-01  5.05524457e-01 -5.20110615e-02]\n"
     ]
    }
   ],
   "source": [
    "# we need to modify the data. Each row represents the xyz coordinates of several points on a hand\n",
    "# we will convert this into a series of distances between the points and the center of the hand\n",
    "normalized_df = pd.DataFrame()\n",
    "# get the center of the hand\n",
    "first = True\n",
    "for row in df.iterrows():\n",
    "    # get the xyz coordinates of the points\n",
    "    if first:\n",
    "        print(row[1][:].values)\n",
    "        print(row[1][:-1].values)\n",
    "        first = False\n",
    "    points = row[1][:-1].values.reshape(-1, 3)\n",
    "    # get the center of the hand\n",
    "    center = np.mean(points, axis=0)\n",
    "    # get the distances between the points and the center\n",
    "    distances = np.linalg.norm(points - center, axis=1)\n",
    "    # add the distances to the normalized dataframe\n",
    "    normalized_df = pd.concat([normalized_df, pd.DataFrame(distances).T])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000   \nmean      0.168880     0.135518     0.092419     0.070245     0.078422   \nstd       0.039238     0.037373     0.034306     0.030727     0.031394   \nmin       0.038313     0.030872     0.022458     0.001777     0.007949   \n25%       0.140355     0.108687     0.065736     0.045820     0.056440   \n50%       0.163896     0.128998     0.084116     0.069041     0.074566   \n75%       0.194633     0.158656     0.115661     0.088772     0.096883   \nmax       0.271586     0.242121     0.192109     0.169416     0.160228   \n\n                5            6            7            8            9   ...  \\\ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000  ...   \nmean      0.062430     0.080998     0.092487     0.110193     0.049627  ...   \nstd       0.013824     0.021424     0.038436     0.054275     0.019953  ...   \nmin       0.002870     0.011499     0.007262     0.002656     0.009778  ...   \n25%       0.052694     0.067097     0.058526     0.059297     0.035693  ...   \n50%       0.060650     0.080629     0.088747     0.107295     0.043712  ...   \n75%       0.070891     0.092415     0.123537     0.156276     0.057363  ...   \nmax       0.114997     0.146094     0.210620     0.263544     0.119883  ...   \n\n                11           12           13           14           15  \\\ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000   \nmean      0.069930     0.089970     0.054527     0.052702     0.055431   \nstd       0.043893     0.063577     0.018517     0.020980     0.028128   \nmin       0.006704     0.004441     0.008384     0.005722     0.003783   \n25%       0.032528     0.034391     0.040797     0.037143     0.034840   \n50%       0.054058     0.068965     0.050821     0.046897     0.045515   \n75%       0.111149     0.157310     0.064120     0.067974     0.070391   \nmax       0.166165     0.220927     0.115243     0.118714     0.149044   \n\n                16           17           18           19           20  \ncount  6111.000000  6111.000000  6111.000000  6111.000000  6111.000000  \nmean      0.074259     0.076923     0.068345     0.074658     0.087115  \nstd       0.041497     0.015087     0.019747     0.027200     0.036576  \nmin       0.002551     0.007935     0.010838     0.014071     0.013151  \n25%       0.046042     0.066589     0.054724     0.057067     0.061895  \n50%       0.061525     0.078056     0.062134     0.069940     0.076313  \n75%       0.088147     0.088172     0.081652     0.083545     0.104001  \nmax       0.203736     0.121115     0.141722     0.183354     0.221810  \n\n[8 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>...</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n      <td>6111.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.168880</td>\n      <td>0.135518</td>\n      <td>0.092419</td>\n      <td>0.070245</td>\n      <td>0.078422</td>\n      <td>0.062430</td>\n      <td>0.080998</td>\n      <td>0.092487</td>\n      <td>0.110193</td>\n      <td>0.049627</td>\n      <td>...</td>\n      <td>0.069930</td>\n      <td>0.089970</td>\n      <td>0.054527</td>\n      <td>0.052702</td>\n      <td>0.055431</td>\n      <td>0.074259</td>\n      <td>0.076923</td>\n      <td>0.068345</td>\n      <td>0.074658</td>\n      <td>0.087115</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.039238</td>\n      <td>0.037373</td>\n      <td>0.034306</td>\n      <td>0.030727</td>\n      <td>0.031394</td>\n      <td>0.013824</td>\n      <td>0.021424</td>\n      <td>0.038436</td>\n      <td>0.054275</td>\n      <td>0.019953</td>\n      <td>...</td>\n      <td>0.043893</td>\n      <td>0.063577</td>\n      <td>0.018517</td>\n      <td>0.020980</td>\n      <td>0.028128</td>\n      <td>0.041497</td>\n      <td>0.015087</td>\n      <td>0.019747</td>\n      <td>0.027200</td>\n      <td>0.036576</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.038313</td>\n      <td>0.030872</td>\n      <td>0.022458</td>\n      <td>0.001777</td>\n      <td>0.007949</td>\n      <td>0.002870</td>\n      <td>0.011499</td>\n      <td>0.007262</td>\n      <td>0.002656</td>\n      <td>0.009778</td>\n      <td>...</td>\n      <td>0.006704</td>\n      <td>0.004441</td>\n      <td>0.008384</td>\n      <td>0.005722</td>\n      <td>0.003783</td>\n      <td>0.002551</td>\n      <td>0.007935</td>\n      <td>0.010838</td>\n      <td>0.014071</td>\n      <td>0.013151</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.140355</td>\n      <td>0.108687</td>\n      <td>0.065736</td>\n      <td>0.045820</td>\n      <td>0.056440</td>\n      <td>0.052694</td>\n      <td>0.067097</td>\n      <td>0.058526</td>\n      <td>0.059297</td>\n      <td>0.035693</td>\n      <td>...</td>\n      <td>0.032528</td>\n      <td>0.034391</td>\n      <td>0.040797</td>\n      <td>0.037143</td>\n      <td>0.034840</td>\n      <td>0.046042</td>\n      <td>0.066589</td>\n      <td>0.054724</td>\n      <td>0.057067</td>\n      <td>0.061895</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.163896</td>\n      <td>0.128998</td>\n      <td>0.084116</td>\n      <td>0.069041</td>\n      <td>0.074566</td>\n      <td>0.060650</td>\n      <td>0.080629</td>\n      <td>0.088747</td>\n      <td>0.107295</td>\n      <td>0.043712</td>\n      <td>...</td>\n      <td>0.054058</td>\n      <td>0.068965</td>\n      <td>0.050821</td>\n      <td>0.046897</td>\n      <td>0.045515</td>\n      <td>0.061525</td>\n      <td>0.078056</td>\n      <td>0.062134</td>\n      <td>0.069940</td>\n      <td>0.076313</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.194633</td>\n      <td>0.158656</td>\n      <td>0.115661</td>\n      <td>0.088772</td>\n      <td>0.096883</td>\n      <td>0.070891</td>\n      <td>0.092415</td>\n      <td>0.123537</td>\n      <td>0.156276</td>\n      <td>0.057363</td>\n      <td>...</td>\n      <td>0.111149</td>\n      <td>0.157310</td>\n      <td>0.064120</td>\n      <td>0.067974</td>\n      <td>0.070391</td>\n      <td>0.088147</td>\n      <td>0.088172</td>\n      <td>0.081652</td>\n      <td>0.083545</td>\n      <td>0.104001</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.271586</td>\n      <td>0.242121</td>\n      <td>0.192109</td>\n      <td>0.169416</td>\n      <td>0.160228</td>\n      <td>0.114997</td>\n      <td>0.146094</td>\n      <td>0.210620</td>\n      <td>0.263544</td>\n      <td>0.119883</td>\n      <td>...</td>\n      <td>0.166165</td>\n      <td>0.220927</td>\n      <td>0.115243</td>\n      <td>0.118714</td>\n      <td>0.149044</td>\n      <td>0.203736</td>\n      <td>0.121115</td>\n      <td>0.141722</td>\n      <td>0.183354</td>\n      <td>0.221810</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# we will create a neural network with 2 hidden layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(21,)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(48, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(24, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# use xgb regressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_2 = XGBRegressor(learning_rate=0.1, n_estimators=100, max_depth=3, min_child_weight=1, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27)\n",
    "\n",
    "# use random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_3 = RandomForestRegressor()\n",
    "\n",
    "# use linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_4 = LinearRegression()\n",
    "\n",
    "# use a decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_5 = DecisionTreeRegressor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# use test train split to split the data into training and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = normalized_df\n",
    "y = df[\"symbol\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1949 - accuracy: 0.0393\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1949 - accuracy: 0.0393\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1949 - accuracy: 0.0393\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 11.2971 - mean_absolute_error: 11.2971 - mean_squared_error: 175.1948 - accuracy: 0.0393\n"
     ]
    },
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    loss='mean_absolute_error',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['mean_absolute_error', 'mean_squared_error', 'accuracy']\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "model_2.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "model_3.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "model_4.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "model_5.fit(\n",
    "    X_train, y_train\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 11.5010 - mean_absolute_error: 11.5010 - mean_squared_error: 179.8212 - accuracy: 0.0458\n"
     ]
    },
    {
     "data": {
      "text/plain": "[11.500953674316406,\n 11.500953674316406,\n 179.82119750976562,\n 0.04575163498520851]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.955179910746305"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9907190423335627"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5024810582084747"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9593454916783885"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([11.984345  ,  9.28834   ,  9.356735  , 18.666668  ,  2.20147   ,\n        1.1652468 , 15.969303  , 11.278209  , 12.212861  , 20.398632  ,\n        7.8426433 , 18.797897  , 11.589216  , 22.290146  ,  7.5565186 ,\n       10.267158  , 11.023238  , 14.457974  , 17.573338  , 18.54646   ,\n       10.463958  , 11.869989  ,  6.0253615 , 20.896784  , 14.355469  ,\n       11.495165  , 18.97626   ,  7.5592318 , 18.34719   , 10.292652  ,\n       22.380877  ,  1.2035023 ,  2.2701275 , 10.122029  ,  9.909293  ,\n       20.019999  , 10.65891   , 10.400291  ,  5.4128895 ,  4.6718655 ,\n       22.056522  ,  7.71025   , 12.944131  , 13.97169   ,  0.9965097 ,\n       19.149408  , 20.48465   , 17.507776  ,  4.2144704 ,  9.810832  ,\n        6.0507007 ,  5.843601  , 13.882627  ,  8.790607  ,  7.6794825 ,\n        9.708336  , 16.432808  ,  9.762485  , 17.78081   , 13.583209  ,\n       19.648167  ,  4.6993127 ,  5.1018014 ,  5.1292834 ,  7.800154  ,\n       18.817059  ,  1.2627147 ,  1.801601  , 19.694162  , 17.179895  ,\n       11.26797   , 11.635331  ,  5.226604  , 15.736006  ,  3.9769247 ,\n       10.996108  ,  8.146902  , 10.340973  , 10.903877  , 17.40052   ,\n       11.339205  ,  5.506982  ,  9.0564785 , 15.93789   , 15.440157  ,\n        3.0933921 ,  6.8373795 , 11.161208  , 17.412546  ,  2.311448  ,\n       11.151004  , 13.520947  , 13.058861  , 21.38404   ,  8.169365  ,\n        1.9081361 ,  0.86726665,  5.554943  , 14.46851   , 10.621251  ,\n       12.209484  , 18.867828  , 18.097     , 18.083576  ,  8.146902  ,\n        8.169365  ,  7.2337203 ,  2.1351202 , 11.704222  ,  4.6608343 ,\n       14.39119   ,  4.8613124 , 14.828964  , 17.14595   , 21.565332  ,\n        9.406252  , 14.1504135 , 17.299072  , 12.735687  , 10.929391  ,\n       17.980501  ,  0.40385115, 16.769148  , 11.82633   ,  9.940012  ,\n       14.725748  ,  5.6647224 ,  7.0439415 ,  9.7755    ,  1.801601  ,\n        4.8152924 , 21.980246  , 15.47201   , 22.09244   , 17.443968  ,\n       21.268139  , 10.883937  ,  1.3137605 , 17.701313  , 10.3824    ,\n       12.707     ,  8.348039  ,  7.709095  , 23.147999  , 15.162313  ,\n       17.443968  , 10.165522  ,  6.741485  , 12.350431  , 12.110578  ,\n       10.691145  ,  9.6082535 ,  2.2592187 ,  9.511863  ,  8.794741  ,\n        4.896645  , 16.769592  ,  9.504783  ,  4.5891843 , 11.605583  ,\n        6.3919406 ,  9.815396  ,  4.193233  ,  2.014828  , 16.032106  ,\n       16.737345  , 17.850788  , 21.822262  ,  4.1757445 , 21.980246  ,\n        9.94429   , 21.306835  , 19.573029  , 15.050392  ,  4.186813  ,\n        1.4430338 ,  7.4930167 , 15.444091  ,  7.947166  , 19.571087  ,\n       21.236563  , 17.752506  , 14.50316   , 18.499239  , 20.923134  ,\n       18.385769  ,  9.538359  , 22.992939  ,  0.78911746, 12.364242  ,\n        7.8906054 , 23.237206  , 15.662537  , 12.876793  ,  9.324856  ,\n       19.781433  ,  1.4132354 ,  8.171442  , 16.432808  , 19.714613  ,\n       19.107105  ,  2.4064527 , 20.588177  , 10.309243  , 21.573784  ,\n       20.478203  , 13.058861  ,  3.2846916 , 20.860504  ,  4.694412  ,\n        8.28153   , 20.961142  ,  1.4539702 ,  3.67197   , 18.758116  ,\n       10.600767  , 10.732885  , 18.963743  , 17.20572   , 21.306835  ,\n        7.5081716 , 10.364374  ,  5.2191167 , 19.620378  ,  4.623905  ,\n        2.2649698 , 11.540082  , 13.464659  , 15.190732  , 11.543502  ,\n       22.387732  , 11.485049  ,  6.6187286 , 11.4396    ,  2.9111958 ,\n       11.752156  ,  7.8426433 ,  9.926032  , 20.195612  , 11.743324  ,\n       11.799313  , 21.85999   ,  1.8356783 , 21.632626  , 11.023238  ,\n        7.899455  , 16.032106  ,  4.3856826 ,  8.14469   ,  9.545988  ,\n       17.713871  , 17.042519  , 12.997237  ,  8.191545  ,  5.4790273 ,\n       19.88224   ,  1.8750745 ,  8.623333  , 13.550369  , 10.396981  ,\n       17.637661  ,  9.549201  ,  1.1490444 , 19.772606  ,  7.2031484 ,\n       15.444091  , 17.507776  ,  2.8337817 , 13.635931  , 16.420246  ,\n       19.30783   , 20.852198  ,  6.7564783 ,  2.7199101 , 15.924944  ,\n       14.494699  ,  1.3121549 , 10.918012  ,  1.8356783 ,  3.794866  ,\n       11.571293  ,  9.188464  ,  6.9583306 , 11.43881   , 12.033931  ,\n        1.8401263 ,  9.041856  , -0.56971025, 21.068777  , 13.704128  ,\n       23.14175   , 17.784138  ,  9.771777  ,  9.817528  , 22.281149  ,\n       15.389867  ,  6.313825  , 23.176987  , -0.20520401,  1.1928555 ,\n       19.337751  , 17.778563  , 19.033392  ,  7.078073  , 10.173106  ,\n       19.819304  , 21.08968   , 18.700096  , 10.354155  , 16.659977  ,\n       19.693499  ,  1.801601  , 18.705374  , 16.075727  ,  1.9081361 ,\n        7.1616373 , 11.210383  ,  6.7695193 ,  1.9569329 , 14.690447  ,\n        3.9875174 , 15.546525  , 17.933395  , 21.866772  , 13.926179  ,\n       12.208241  , 16.876389  , 18.134945  , 19.045284  , 20.400307  ,\n       12.296913  ,  8.31815   ,  9.729488  ,  1.8356783 ,  9.147757  ,\n        9.817528  ,  7.947166  ,  7.550657  , 15.937187  ,  3.5291443 ,\n       10.104934  ,  4.6599364 ,  4.7253137 , 16.161427  ,  8.667472  ,\n        4.117285  , 17.564995  , -0.5798868 ,  7.3747034 , 10.755608  ,\n        1.9081361 , 10.944485  , -0.20520401, 19.275583  ,  3.9248452 ,\n        1.0204887 , 18.510557  ,  8.180973  ,  2.1699114 , 12.852302  ,\n       13.987331  ,  2.7345052 , 10.041097  , 17.542536  ,  1.2035023 ,\n       11.803266  , 19.038094  , 20.488735  , 18.352419  ,  6.734081  ,\n       15.657303  ,  4.8152924 , 16.037931  ,  5.700669  , 15.657016  ,\n        5.554943  , 13.037387  , 21.866772  ,  9.234829  ,  6.943852  ,\n        8.623333  ,  4.8152924 , 23.169624  , 19.644972  , 20.689287  ,\n        1.9916507 , 14.18498   , 15.645113  ,  4.928513  , 12.411195  ,\n        9.454549  , 16.129251  ,  9.336284  ,  3.982338  , 11.896673  ,\n       18.341085  , 16.151072  ,  2.20147   , 17.024065  ,  4.714593  ,\n        1.9052101 , 12.043315  , 19.12262   , 20.927603  ,  3.9176528 ,\n        9.673628  , 19.261415  , 18.456654  , 10.643057  , 17.651133  ,\n        1.4690452 , 19.373362  ,  1.5977815 , 15.47201   ,  4.899944  ,\n        7.0237536 ,  9.563507  ,  0.42412993,  0.9707086 , 16.867136  ,\n        4.0270624 ,  0.39427227, 16.381079  , 15.298566  , 16.003168  ,\n       10.339009  , 11.788615  ,  1.8184805 , 11.620543  , 20.88604   ,\n        6.8897667 ,  5.009874  , 16.581518  , 10.621251  , 16.530287  ,\n       17.676378  ,  7.54578   , 11.450622  ,  6.7395024 ,  8.18698   ,\n       16.050278  , 20.061146  ,  1.754875  , 11.179908  ,  4.486505  ,\n       19.933502  ,  2.1768336 , 13.27919   , 14.245738  , 19.614147  ,\n        9.413386  , 12.482031  , 18.684757  ,  5.586167  ,  1.1484073 ,\n       19.245089  ,  8.146902  ,  1.9081361 , 17.288961  , 18.874199  ,\n       16.847914  ,  8.0503235 ,  9.36142   ,  6.7171307 ,  3.590329  ,\n       21.809332  ,  8.758898  , 19.647678  ,  6.799342  ,  5.1216154 ,\n       18.580582  , 22.116669  ,  1.1484073 ,  7.892295  ,  3.6859994 ,\n       17.020102  ,  3.4130352 ,  5.804013  , 21.660599  , 13.84663   ,\n       13.529349  ,  5.706729  , 19.218765  ,  6.5156574 , 18.656473  ,\n        2.4690404 ,  7.689082  , 18.805065  , 21.511217  ,  2.8510697 ,\n       19.12968   , 15.936248  , 13.664444  , 19.195095  ,  5.7006645 ,\n        7.9383125 , 14.18498   ,  9.950235  ,  2.2865195 , 14.177706  ,\n       21.980246  ,  9.413386  , 21.553623  ,  0.3748173 , 15.68257   ,\n       14.442523  , 14.783895  , 11.374174  , 13.384116  , 10.95448   ,\n       13.734992  , 11.328546  , 20.488588  ,  4.299202  , 23.227148  ,\n       19.430494  ,  6.7695193 , 10.168755  , 16.156921  , 11.910887  ,\n        3.462124  ,  9.834223  , 17.965525  , 21.147978  ,  4.965891  ,\n       18.967487  ,  4.7253137 ,  7.1235647 , 18.839891  , 22.972076  ,\n       13.153403  ,  8.113045  ,  2.8414032 , 19.883146  , 19.950357  ,\n        4.0944886 ,  1.4684706 , 10.523093  ,  3.5500288 , 16.302248  ,\n       -0.56971025, 16.610773  , 16.093138  ,  2.2056541 , 11.646204  ,\n       15.785707  , 15.836797  ,  1.8059901 , 14.534912  , 11.466602  ,\n       10.318834  , 12.949359  ,  7.338291  , 16.705912  ,  3.7259898 ,\n        2.3498003 , 12.8612175 , 18.482504  ,  2.8889399 ,  3.83895   ,\n       23.104248  ,  7.73655   , 19.689728  ,  8.623333  , 12.526781  ,\n       21.716183  , 13.570393  , 10.503077  ,  8.358176  ,  1.8750745 ,\n        0.9697565 ,  6.639868  ,  1.2833021 ,  7.608301  , 16.170036  ,\n       17.3595    , 13.607605  ,  4.51021   ,  1.9963347 , 19.692497  ,\n       21.491844  ,  2.0189257 ,  1.8073637 , 15.927772  ,  6.1818457 ,\n       16.530287  , 22.61942   , 16.74471   , 10.214587  ,  7.192556  ,\n        3.349221  ,  3.7706428 ,  6.2512784 ,  5.660545  , 12.387695  ,\n       19.605125  ,  8.931187  ,  4.104243  ,  9.718524  , 14.771631  ,\n       15.090806  , 10.089411  , 22.387732  , 13.8285885 , 11.26797   ,\n       21.96803   , 14.605444  ,  7.70075   , 11.1150055 , 23.005701  ,\n        8.190191  , 11.570095  ], dtype=float32)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([12.99,  8.  ,  9.84, 20.8 ,  2.  ,  0.  , 18.78, 12.84, 10.87,\n       21.81,  6.96, 18.53, 12.82, 23.  ,  7.99, 12.16, 10.  , 12.88,\n       18.  , 19.  , 11.25, 13.6 ,  3.  , 22.  , 14.96, 13.  , 17.12,\n        7.99, 16.97, 11.65, 22.85,  1.  ,  3.07, 10.  ,  9.  , 19.87,\n       11.  , 10.4 ,  3.98,  4.  , 21.  ,  7.33, 12.23, 15.  ,  1.  ,\n       19.04, 21.  , 17.  ,  4.51,  8.  ,  7.  ,  3.  , 14.64,  7.72,\n        7.04,  7.1 , 16.95,  8.  , 15.99, 15.  , 21.  ,  3.  ,  5.  ,\n        5.  ,  7.14, 18.93,  0.  ,  2.  , 19.83, 17.18, 13.  , 11.  ,\n        3.  , 17.82,  3.  , 11.  ,  8.  , 12.01,  7.02, 18.42, 11.  ,\n        8.89,  9.  , 17.9 , 16.37,  2.24,  3.  , 14.  , 16.26,  3.01,\n       11.01, 12.97, 12.11, 22.  ,  8.  ,  2.  ,  0.  ,  6.06, 16.97,\n       10.  , 13.  , 21.  , 15.99, 16.24,  8.  ,  8.  ,  7.  ,  1.  ,\n       11.  ,  4.  , 16.08,  5.  , 12.89, 18.  , 22.  ,  9.01, 13.98,\n       16.  , 12.  ,  9.16, 20.8 ,  0.  , 17.01, 14.03, 12.82, 15.12,\n        6.98,  7.  , 10.  ,  2.  ,  5.  , 22.  , 16.14, 23.  , 16.11,\n       22.39,  8.37,  1.  , 16.36, 10.93, 13.  ,  9.  ,  4.17, 23.  ,\n       15.02, 16.  ,  8.  ,  6.  , 12.  , 10.92, 11.  ,  9.06,  2.  ,\n       10.  , 10.  ,  5.  , 17.66,  9.  ,  2.3 , 10.  ,  6.03,  8.04,\n        3.2 ,  0.24, 16.  , 16.94, 18.  , 22.  ,  3.07, 22.  ,  9.  ,\n       22.  , 21.81, 16.59,  4.  ,  1.  ,  8.89, 15.  ,  6.  , 19.6 ,\n       21.  , 16.18, 15.29, 19.06, 21.56, 18.97, 10.  , 23.  ,  0.48,\n       11.  ,  9.1 , 23.  , 21.71, 13.  ,  9.  , 19.9 ,  1.  ,  8.98,\n       16.95, 19.98, 19.1 ,  1.  , 21.  ,  9.  , 15.89, 21.82, 12.05,\n        3.12, 21.  ,  3.  ,  8.12, 21.83,  0.  ,  4.18, 18.64, 11.  ,\n       10.  , 18.92, 19.91, 22.  ,  7.99, 11.  ,  4.14, 19.75,  5.  ,\n        0.03, 11.95, 13.47, 15.  ,  8.36, 22.  , 11.  ,  6.97, 11.  ,\n        0.22, 12.95,  6.97,  9.97, 20.68, 12.08, 12.29, 22.74,  2.  ,\n       22.  , 10.  ,  7.26, 16.  ,  4.1 ,  7.02,  8.  , 17.94, 16.69,\n       12.51,  8.98,  5.  , 21.  ,  2.  ,  9.  , 13.98, 10.04, 16.94,\n        9.  ,  0.  , 19.  ,  7.  , 15.  , 17.  ,  3.  , 14.66, 15.76,\n       19.3 , 23.  ,  6.07,  2.  , 15.04, 14.36,  1.  , 10.  ,  2.  ,\n        4.  , 11.02,  9.  ,  6.03, 13.02, 14.  ,  2.02,  9.52,  0.  ,\n       21.82, 13.93, 23.  , 16.23,  8.15,  8.15, 23.  , 14.  ,  6.  ,\n       23.  ,  0.  ,  1.  , 21.  , 16.98, 21.92,  7.04, 11.86, 23.  ,\n       21.  , 19.98, 10.85, 16.  , 19.48,  2.  , 18.  , 16.81,  2.  ,\n        8.04, 12.67,  6.06,  3.07, 15.  ,  4.  , 14.  , 16.06, 22.  ,\n       14.  , 11.  , 16.  , 17.8 , 21.  , 21.  , 13.78,  8.  ,  9.  ,\n        2.  ,  8.22,  8.15,  6.  ,  7.  , 17.05,  3.  ,  8.96,  5.  ,\n        5.  , 18.  ,  7.88,  4.  , 16.22,  0.  ,  7.  , 11.14,  2.02,\n       12.06,  0.  , 19.95,  4.  ,  0.14, 19.05,  6.05,  2.  , 14.71,\n       12.95,  2.  ,  8.51, 17.38,  1.  ,  8.15, 19.02, 21.  , 18.73,\n        6.  , 16.98,  5.  , 16.14,  6.  , 15.  ,  6.  , 14.09, 22.  ,\n        4.75,  7.  ,  9.  ,  5.  , 23.  , 19.71, 21.52,  2.  , 15.13,\n       15.  ,  5.  , 12.  ,  9.94, 15.  ,  8.  ,  3.  , 11.  , 17.57,\n       14.78,  2.  , 17.89,  5.  ,  2.  , 12.12, 19.86, 21.  ,  4.  ,\n        8.21, 19.81, 21.  , 11.  , 18.  ,  0.29, 19.01,  0.  , 15.96,\n        5.  ,  7.  , 10.  ,  0.  ,  1.  , 17.99,  3.  ,  0.  , 18.  ,\n       16.93, 17.  ,  8.98, 13.35,  1.8 , 12.  , 21.  ,  4.09,  3.  ,\n       18.  , 10.  , 17.  , 17.  ,  7.99, 13.05,  7.04,  8.87, 16.92,\n       21.  ,  1.2 ,  9.88,  3.2 , 21.  ,  0.  , 11.93, 14.81, 22.7 ,\n       10.2 , 12.06, 20.  ,  5.  ,  0.  , 19.02,  8.  ,  2.  , 18.  ,\n       23.  , 16.  ,  8.  , 10.  ,  7.  ,  4.  , 23.  ,  7.  , 19.99,\n        6.03,  4.3 , 18.8 , 23.  ,  0.  ,  8.04,  4.  , 16.43,  4.31,\n        3.  , 23.  , 13.6 , 13.  ,  6.  , 19.2 ,  7.96, 20.65,  1.  ,\n        8.  , 18.38, 21.81,  3.  , 19.05, 18.  , 13.  , 20.75,  4.33,\n        6.16, 15.  , 10.  ,  3.  , 13.98, 22.  , 10.1 , 23.  ,  0.  ,\n       15.17, 15.  , 14.81, 10.  , 17.44, 10.  , 10.29, 11.  , 21.  ,\n        4.15, 23.  , 21.  ,  6.06, 12.96, 17.94, 12.95,  4.05,  8.88,\n       16.38, 22.  ,  4.  , 21.  ,  5.  ,  7.01, 22.7 , 22.85, 14.01,\n        6.97,  2.  , 21.77, 19.19,  4.  ,  3.  , 11.01,  4.  , 16.93,\n        0.04, 16.53, 16.58,  2.02, 11.  , 17.  , 16.54,  3.01, 14.76,\n       11.  , 10.  , 13.88,  6.03, 16.25,  4.  ,  3.  , 14.  , 19.77,\n        1.4 ,  3.29, 23.  ,  9.02, 19.87,  9.  , 14.96, 22.  , 13.  ,\n       10.91,  8.15,  2.  ,  1.  ,  6.18,  1.  ,  6.19, 17.39, 18.  ,\n       14.01,  4.  ,  1.  , 19.96, 22.  ,  1.24,  0.  , 17.  ,  4.  ,\n       17.  , 22.78, 16.  ,  9.1 ,  7.81,  2.  ,  3.32,  6.31,  4.25,\n       13.  , 18.82, 10.16,  4.05,  8.03, 15.02, 15.74, 12.82, 22.  ,\n       13.21, 13.  , 22.  , 15.74,  5.01, 11.  , 23.  ,  8.  , 11.96])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 7.39923889,  5.27365305,  8.47495295,  9.15909141,  2.06758822,\n        4.52129373, 15.18947275,  9.45301648, 12.33298397, 15.60202037,\n       11.69027324, 20.13139257, 10.29175973, 14.32635849, 11.23499407,\n        6.85471553, 10.46509879, 11.85421437, 15.75592008, 16.75876355,\n        8.43026945, 10.44998252,  8.0398401 , 18.4319977 ,  5.90914419,\n        9.81148289, 15.2578573 , 11.55233227, 15.50935469,  3.30912906,\n       17.33473832,  6.60678785,  9.87666074,  9.04257538,  9.83114837,\n       17.91833622, 15.1649101 , 12.88977745, 16.31398296,  2.62807381,\n       12.49766312,  9.6046923 ,  9.53988441, 14.12522064,  4.60915421,\n       19.24660637, 12.8628942 , 14.18743794,  6.47371657, 14.17264598,\n        7.11697632, 11.76859941, 10.56250271, 14.76473319, 14.65508173,\n        8.45235023, 15.90505971, 13.70948389, 23.72343125,  9.42156546,\n       10.41376227,  5.06127047,  6.04821701,  7.1934272 ,  9.5921341 ,\n       18.8499255 ,  6.80943889,  7.46860984, 15.01578267, 14.86903212,\n       10.80461489, 10.41959645, 10.97022493, 16.51484268,  6.09159759,\n       13.53881161, 12.52509517,  5.12641228,  9.63141453, 16.85722825,\n        4.92765313,  9.57433226, 12.03231372, 17.7004881 , 15.59763191,\n        9.74206997,  5.84158786, 11.24684448, 21.46232368,  6.753927  ,\n        8.01618274, 10.86317108, 13.61054033, 17.12406706,  8.65491791,\n        8.35064129,  5.66104929,  9.05989662, 13.21781737,  9.43225249,\n       10.63867401, 11.669839  , 19.42546829, 19.68591568, 13.08364779,\n        9.6674617 ,  8.48049789,  1.5911599 ,  8.59661813,  6.34228301,\n       12.1006353 ,  7.1920021 ,  9.05706701, 16.91007428, 17.36465647,\n       11.96907516, 13.30061911, 20.23989323, 18.55272223, 15.34097161,\n        9.94863974,  7.00229743, 13.56064937, 10.60612269,  6.84620036,\n       13.94021839,  6.88575988,  7.35224924,  9.16029899,  6.93803465,\n        4.10031881, 17.2147454 , 21.3990426 , 14.48149241, 21.66593054,\n       14.18875199, 14.92949406,  0.46381978, 19.70568626,  4.97775074,\n        8.22375464,  8.88321109,  8.14367884, 11.30437002, 13.85820518,\n       23.10498008,  5.13101145, 14.37463389, 17.34910741, 12.63100826,\n       14.86303208,  9.17152578,  7.92619652,  9.14648718,  8.78420464,\n        8.5533185 , 15.77993564,  9.02718297, 10.50275189,  6.32226894,\n        5.76228324,  9.8500365 ,  6.07239287,  2.12432026, 16.01664897,\n       15.30280331, 13.9036949 , 18.76007573,  3.58160126, 17.35322453,\n       12.23698793, 19.96512603, 17.47724855, 18.91658265,  9.18251841,\n        5.44840225, 11.5054243 , 12.92650148, 13.24181294, 15.42900975,\n       11.36033487, 19.61887817, 14.77723164, 16.91799712, 20.05136954,\n       19.54544213,  4.35408309, 15.12098606,  2.78782873, 12.43583116,\n        6.6799396 , 17.06210247, 13.78787186,  9.01733457,  9.85545345,\n       19.64979816,  7.18379673,  5.72026179, 16.01355482, 18.06081036,\n       17.38857569,  1.84868343, 10.12908526, 12.50239954, 16.84486644,\n       17.55050288, 13.81190435,  0.7636105 ,  9.71140096,  9.78246334,\n        5.21206639, 17.01377085,  1.80220106, 11.04654688, 20.19240236,\n       15.02602348,  9.70397347, 19.93374973, 17.36670081, 19.12981398,\n       11.89430774, 15.57932169,  9.07013026, 21.52920596,  4.76767849,\n        4.80582449, 11.09106906, 16.41076045,  9.93723142,  7.13565113,\n       18.47339656, 11.57404163, 12.99267305, 13.49679713, 10.66651236,\n        6.87898776, 11.85892021, 11.82046432, 15.02326127, 10.31909859,\n        9.22508482, 13.16142666,  8.51722503, 18.08486332,  7.63211724,\n       11.34982139, 17.5841156 , 14.7727502 ,  9.9443175 , 15.4161219 ,\n       15.74356536, 19.84245923,  3.01191781, 11.40435011,  8.60174876,\n       10.88748921,  8.45125602, 12.56992714, 11.01854311,  9.03106787,\n       15.25728002, 14.24200596,  3.56351967, 25.04165444,  6.05731564,\n       12.71054452, 14.90520939,  5.78700286, 14.9065784 , 14.87774494,\n       21.44386033, 12.98114628, 10.74738531,  9.24408801, 13.26870465,\n       12.11329833,  7.23611836,  8.18954424,  8.57540197,  3.56332496,\n        5.78078322, 14.74971827, 13.4247302 ,  7.62034617, 14.8809427 ,\n        8.24631035, 15.87826746,  5.66950061, 15.2610177 , 18.78569096,\n       14.12609057, 19.22096889, 14.10114828, 15.75826388, 15.5328676 ,\n       14.027368  ,  9.33746551, 16.59468446,  6.55003902,  6.46968866,\n       12.98980115, 17.48909353, 17.46839529,  9.09899007,  7.07272914,\n       13.03449439, 11.41460499, 14.73205227, 19.7371179 , 19.83221985,\n       16.47268017,  8.29591574, 16.38414194, 16.00439468,  5.35936392,\n        4.43942366, 10.12989584, 12.88342489,  9.29557523, 13.02497825,\n        0.65293328, 14.21304286, 20.07816666, 17.52743113, 14.44568328,\n        8.10353955, 20.60259066, 15.67097847,  8.82320745, 15.1601927 ,\n       11.74824944, 15.31802464, 12.61658552,  8.17367351, 15.47692929,\n       15.81064155, 13.54657924,  9.97920556, 16.34530711,  6.14326471,\n       12.53461093,  7.69489062,  7.6029689 , 16.69603701,  7.97489352,\n        2.39726455, 19.80516619,  5.0723584 ,  9.39957487, 11.17425523,\n        8.44420188,  6.68520849,  6.27721318, 20.46745342,  8.04233641,\n        2.36526218, 23.55222744, 15.14641551,  6.17301547, 11.44516078,\n        9.56468694,  7.73256799,  8.1365582 , 14.03589598,  6.85572644,\n       14.97408658, 16.53912658,  8.8576212 , 19.20438242, 10.42142389,\n       16.95076832,  4.88790336, 10.91891745,  8.4328726 , 12.98551115,\n        9.27250421, 10.85714917, 16.41356213, 14.07435199, 10.08443599,\n       12.7345566 ,  6.75300901, 11.0789652 , 14.63391353, 13.97217417,\n        8.26835737,  6.06639226, 13.39458908,  6.14495118, 18.89712654,\n        6.51775756, 12.5241851 ,  4.08384926,  6.70992063, 11.65182213,\n       16.66944616, 14.8501505 ,  4.50144812, 14.09733874,  8.33386753,\n        7.73583059,  9.15032583, 16.97939849,  8.34527912, -1.05342457,\n        6.89247838, 16.33888965, 11.40731278, 11.83788208, 17.8026104 ,\n       -0.89914872, 15.08223655,  5.67401123, 22.66441503,  7.67503963,\n        6.62636193, 11.09925233,  5.7918838 ,  5.15231692, 16.51883997,\n        4.24220553,  2.02815349, 15.87951614, 18.10385403, 15.07024569,\n       12.32269178, 11.24704614, -0.87566765,  9.15443205,  9.07742621,\n        8.1017235 ,  9.52537196, 16.25043728,  8.80378417, 14.09526199,\n       13.85608359, 12.28468154,  9.46279799,  6.99770458, 13.79236418,\n       14.0702247 , 11.27668763, -1.30055702,  8.36083177,  9.28174169,\n       10.5543299 ,  5.49215688, 13.3912499 ,  8.89711316, 14.50698509,\n       11.21071822, 11.71895196, 14.41644118,  6.8357624 ,  3.25675025,\n       19.15501853, 12.99950504,  5.79904642, 16.21280148, 15.14954607,\n       23.11195933, 11.73365039, 11.46355397,  5.89460539,  3.96416492,\n       14.1133042 ,  8.5690196 , 19.16993733, 12.20320197,  7.10974183,\n       14.4921178 , 16.19897411,  3.5211723 ,  6.15975599,  7.87682837,\n       14.00178661, 10.54311025,  5.90214887, 17.38637636, 10.4086779 ,\n        9.47016742,  8.52135476, 13.71480243, 12.32605961, 10.79179281,\n        3.50946598, 13.74407485, 19.00463224, 17.7331632 ,  0.658462  ,\n       19.1483682 , 16.61348144,  7.81097945,  9.60332968,  6.82174461,\n       12.4147561 ,  6.10001537, 10.4592653 ,  7.3631348 , 14.54167011,\n       16.62933219, 11.08828079, 14.02752728,  6.61533332, 13.96119015,\n       12.55054167, 10.63608921,  6.51543992, 15.2971964 ,  8.2449019 ,\n        9.35716406, 13.4215887 , 10.3573155 , -1.37294699, 13.87509304,\n       12.44826854, 13.49979755,  9.1396578 , 15.72925596,  7.33616408,\n        9.61701663, 14.92174631, 20.32222653, 16.98558613,  3.87677009,\n       11.3743974 ,  7.46125017,  9.79444226, 12.68044283, 13.3693937 ,\n       14.33452269,  8.47521374,  6.46060925, 16.89343613, 19.68588752,\n        3.55837516,  6.29236308,  8.40637883,  3.0889438 , 13.47553064,\n        6.56276463, 23.70591654, 14.40730805,  8.31026779,  9.85565495,\n       16.95278202, 17.66655741, 12.54418417, 13.60133769, 13.13752987,\n        5.30736009, 17.57770501, 14.36454534, 18.9165882 ,  6.02803858,\n        5.45679199, 12.36566129, 14.80387313,  2.67409211,  2.2179506 ,\n       17.17504665,  5.73717624, 17.15664364, 12.66342603, 15.70984538,\n       18.89577904,  7.20501066,  8.94338603, 10.01557972,  8.3888734 ,\n        3.55523222,  8.45901367,  2.42184408,  8.38613837, 15.6737445 ,\n       15.87287715, 11.2577435 ,  8.31680566,  3.51674171, 17.19453916,\n       20.72035512, -1.08389574,  1.73111706, 17.70461638,  8.05554904,\n       14.48683364, 11.15760315, 20.4302574 ,  7.95825197, 10.16746952,\n        9.26263843,  4.0536612 ,  5.65697346, 16.11912085, 10.41200636,\n       15.33639217, 14.17981294,  8.30227847, 14.56581091, 13.10400067,\n       12.21684298,  8.45767741, 17.84294528, 13.59236031, 10.71507341,\n       18.43359075, 12.77314927,  8.53687409, 10.31247246, 13.19420338,\n       13.27298807,  9.61816534])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([13.,  8., 10., 21.,  2.,  0., 21., 13., 11., 22.,  7., 19., 13.,\n       23.,  8., 13., 10., 12., 18., 19., 11.,  4.,  3., 22., 15., 13.,\n       17.,  8., 17., 12., 23.,  1.,  3., 10.,  9., 20., 11.,  4.,  4.,\n        4., 21.,  7., 13., 15.,  1., 19., 21., 17.,  4.,  8.,  7.,  3.,\n       15.,  7.,  7.,  7., 17.,  8., 16., 15., 21.,  3.,  5.,  5.,  7.,\n       19.,  0.,  2., 20., 17., 13., 11.,  3., 18.,  3., 11.,  8., 12.,\n        7., 22., 11.,  9.,  9., 18., 17.,  2.,  3., 14., 16.,  3., 11.,\n       14., 12., 22.,  8.,  2.,  0.,  6., 17., 10., 13., 21., 16., 16.,\n        8.,  8.,  7.,  1., 11.,  4., 15.,  5., 13., 18., 22.,  9., 14.,\n       16., 12.,  8., 21.,  0., 17., 14., 13., 22.,  7.,  7., 10.,  2.,\n        5., 22., 16., 23., 16., 23.,  8.,  1., 16., 11., 13.,  9.,  4.,\n       23., 15., 16.,  8.,  6., 12., 11., 11.,  9.,  2., 10., 10.,  5.,\n       18.,  9.,  2., 10.,  6.,  8.,  3.,  0., 16., 17., 18., 22.,  3.,\n       22.,  9., 22., 22., 15.,  4.,  1.,  9., 15.,  6., 20., 21., 16.,\n       14., 19., 22., 19., 10., 23.,  0., 11.,  9., 23., 23., 13.,  9.,\n       20.,  1.,  9., 17., 20., 19.,  1., 21.,  9.,  0., 22., 12.,  3.,\n       21.,  3.,  8., 22.,  0.,  3., 19., 11., 10., 19., 20., 22.,  8.,\n       11.,  2., 19.,  5.,  0., 14., 14., 15.,  7., 22., 11.,  7., 11.,\n        0., 13.,  7.,  9., 21., 12., 12., 23.,  2., 22., 10.,  7., 16.,\n        4.,  7.,  8., 18., 16., 12.,  9.,  5., 21.,  2.,  9., 14., 10.,\n       17.,  9.,  0., 19.,  7., 15., 17.,  3., 15., 12., 19., 23.,  6.,\n        2., 15., 15.,  1., 10.,  2.,  4., 11.,  9.,  6., 13., 14.,  2.,\n        8.,  0., 22., 14., 23., 16.,  8.,  8., 23., 14.,  6., 23.,  0.,\n        1., 21., 17., 22.,  7., 13., 23., 21., 20., 11., 16., 19.,  2.,\n       18., 17.,  2.,  4., 13.,  6.,  3., 15.,  4., 14., 16., 22., 14.,\n       11., 16., 18., 21., 21., 14.,  8.,  9.,  2.,  8.,  8.,  6.,  7.,\n       17.,  3.,  9.,  5.,  5., 18.,  8.,  4., 16.,  0.,  7., 11.,  2.,\n       12.,  0., 20.,  4.,  0., 19.,  6.,  2., 14., 13.,  2.,  8.,  9.,\n        1.,  8., 19., 21., 19.,  6., 17.,  5., 18.,  6., 15.,  6., 15.,\n       22.,  2.,  7.,  9.,  5., 23., 20., 22.,  2., 14., 15.,  5., 12.,\n       10., 15.,  8.,  3., 11., 17., 14.,  2., 18.,  5.,  2., 12., 20.,\n       21.,  4.,  8., 20., 21., 11., 18.,  0., 19.,  0., 16.,  5.,  7.,\n       10.,  0.,  1., 18.,  3.,  0., 18., 17., 17.,  9., 14.,  1., 12.,\n       21.,  4.,  3., 18., 10., 17., 17.,  8., 13.,  7.,  9., 17., 21.,\n        1., 10.,  3., 21.,  0., 10., 14., 23., 10., 12., 20.,  5.,  0.,\n       19.,  8.,  2., 18., 23., 16.,  8., 10.,  7.,  4., 23.,  7., 20.,\n        6.,  4., 19., 23.,  0.,  8.,  4., 17.,  4.,  3., 23., 14., 13.,\n        6., 19.,  8., 23.,  1.,  8., 16., 22.,  3., 19., 18., 13., 21.,\n        4.,  6., 15., 10.,  3., 14., 22., 10., 23.,  0., 15., 15., 17.,\n       10., 20., 10., 13., 11., 21.,  4., 23., 21.,  6., 13., 18., 13.,\n        4.,  9., 16., 22.,  4., 21.,  5.,  7., 23., 23., 14.,  7.,  2.,\n       22., 19.,  4.,  3., 11.,  4., 17.,  0., 17., 17.,  2., 11., 17.,\n       16.,  3., 15., 11., 10., 17.,  6., 16.,  4.,  3., 14., 20.,  1.,\n        3., 23.,  9., 20.,  9., 15., 22., 13., 14.,  8.,  2.,  1.,  6.,\n        1., 14., 18., 18., 14.,  4.,  1., 20., 22.,  1.,  0., 16.,  4.,\n       17., 23., 16.,  9.,  8.,  2.,  3.,  6.,  4., 13., 19., 17.,  4.,\n        8., 15., 18., 13., 22., 14., 13., 22., 15.,  4., 11., 23.,  8.,\n       12.])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "183    13\n132     8\n36     10\n72     21\n189     2\n       ..\n22      4\n191    11\n45     23\n22      8\n243    12\nName: symbol, Length: 612, dtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# save model 5\n",
    "\n",
    "# pickle.dump(model_5, open(\"model_5.sav\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model = pickle.load(open(\"{{model_name}}.sav\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# we need to modify the data. Each row represents the xyz coordinates of several points on a hand\n",
    "# we will convert this into a series of distances between the points and the center of the hand\n",
    "test_data = pd.read_csv(\"testing_data_abcs.csv\")\n",
    "# test_data = pd.read_csv(\"training_data_0/C.csv\")\n",
    "test_data.drop(columns=[\"'symbol'\"], inplace=True)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "# get the center of the hand\n",
    "for row in test_data.iterrows():\n",
    "    # get the xyz coordinates of the points\n",
    "    points = row[1][:].values.reshape(-1, 3)\n",
    "    # get the center of the hand\n",
    "    center = np.mean(points, axis=0)\n",
    "    # get the distances between the points and the center\n",
    "    distances = np.linalg.norm(points - center, axis=1)\n",
    "    # add the distances to the normalized dataframe\n",
    "    test_df = pd.concat([test_df, pd.DataFrame(distances).T])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0., 11., 11., 11.,  0.,  0.,  0.,  4.,  3.,  1.,  1.,  1.,\n        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n        1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,\n        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n        2.,  2.,  2.,  2., 12.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,  2.,  2.,\n        2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,\n        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n        4.,  4.,  4.,  4.,  4.,  2.,  4.,  4.,  4.,  4.,  4.,  2.,  2.,\n        2.,  2.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n        5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,  3.,  3.,  3.,  3.,\n        3., 13.,  3., 13.])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_5.predict(test_df)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# round the predictions\n",
    "predictions = np.round(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# get the letter for each prediction\n",
    "letters = [num_to_letter[int(prediction)] for prediction in predictions]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A, M, A, E, D, B, C, N, D, C, E, C, E, C, E, F, G, D, O, D, O, "
     ]
    }
   ],
   "source": [
    "prev = None\n",
    "for letter in letters:\n",
    "    if prev is None:\n",
    "        print(letter, end=\", \")\n",
    "        prev = letter\n",
    "    else:\n",
    "        if prev != letter:\n",
    "            print(letter, end=\", \")\n",
    "            prev = letter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
